{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "533a88bb",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0481e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Lambda, Activation\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from functools import reduce\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "\n",
    "# Constants\n",
    "CROP_SIZE = 113\n",
    "NUM_LABELS = 50\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cda934",
   "metadata": {},
   "source": [
    "## Create Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfde8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the autoencoder\n",
    "def create_autoencoder():\n",
    "    input_img = Input(shape=(CROP_SIZE, CROP_SIZE, 1))\n",
    "    encoded = Dense(128, activation='relu')(input_img)\n",
    "    encoded = Dense(64, activation='relu')(encoded)\n",
    "    encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "    decoded = Dense(64, activation='relu')(encoded)\n",
    "    decoded = Dense(128, activation='relu')(decoded)\n",
    "    decoded = Dense(1, activation='sigmoid')(decoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56a3b1",
   "metadata": {},
   "source": [
    "## Extract Features Using Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6cb96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features using the autoencoder\n",
    "def extract_features(encoder_model, data):\n",
    "    data_features = encoder_model.predict(data.reshape((len(data), CROP_SIZE * CROP_SIZE)))\n",
    "    return data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1aae2",
   "metadata": {},
   "source": [
    "## Create Writer Identification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e0d41f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and compile the writer identification model\n",
    "def create_writer_identification_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Define network input shape\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(CROP_SIZE, CROP_SIZE, 1)))\n",
    "    model.add(Lambda(resize_image))\n",
    "\n",
    "    # CNN model\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same', name='conv1'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1'))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', name='conv2'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool2'))\n",
    "\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', name='conv3'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool3'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(512, name='dense1'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(256, name='dense2'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(NUM_LABELS, name='output'))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b174de2",
   "metadata": {},
   "source": [
    "## Generate Data Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad2ddb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate data batches\n",
    "def generate_data(samples, labels, batch_size, sample_ratio):\n",
    "    while 1:\n",
    "        for offset in range(0, len(samples), batch_size):\n",
    "            batch_samples = samples[offset:(offset + batch_size)]\n",
    "            batch_labels = labels[offset:(offset + batch_size)]\n",
    "\n",
    "            # Augment each sample in batch\n",
    "            augmented_batch_samples = []\n",
    "            augmented_batch_labels = []\n",
    "            for i in range(len(batch_samples)):\n",
    "                sample = batch_samples[i]\n",
    "                label = batch_labels[i]\n",
    "                augmented_samples, augmented_labels = get_augmented_sample(sample, label, sample_ratio)\n",
    "                augmented_batch_samples.append(augmented_samples)\n",
    "                augmented_batch_labels.append(augmented_labels)\n",
    "\n",
    "            # Flatten out samples and labels\n",
    "            augmented_batch_samples = reduce(operator.add, augmented_batch_samples)\n",
    "            augmented_batch_labels = reduce(operator.add, augmented_batch_labels)\n",
    "\n",
    "            # Reshape input format\n",
    "            X_train = np.array(augmented_batch_samples)\n",
    "            X_train = X_train.reshape(X_train.shape[0], CROP_SIZE, CROP_SIZE, 1)\n",
    "\n",
    "            # Transform input to float and normalize\n",
    "            X_train = X_train.astype('float32')\n",
    "            X_train /= 255\n",
    "\n",
    "            # Encode y\n",
    "            y_train = np.array(augmented_batch_labels)\n",
    "            y_train = to_categorical(y_train, NUM_LABELS)\n",
    "\n",
    "            yield X_train, y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0bd37",
   "metadata": {},
   "source": [
    "## Resize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4395a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to resize images\n",
    "def resize_image(img):\n",
    "    size = round(CROP_SIZE / 2)\n",
    "    return tf.image.resize(img, [size, size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b54cc0",
   "metadata": {},
   "source": [
    "## Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1870dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Create a dictionary to store each form ID and its writer\n",
    "    form_writer = {}\n",
    "    forms_file_path = \"../data/forms.txt\"\n",
    "    \n",
    "    with open(forms_file_path) as f:\n",
    "        for line in islice(f, 16, None):\n",
    "            line_list = line.split(' ')\n",
    "            form_id = line_list[0]\n",
    "            writer = line_list[1]\n",
    "            form_writer[form_id] = writer\n",
    "\n",
    "    # Select the 50 most common writers\n",
    "    num_writers = 50\n",
    "    writers_counter = Counter(form_writer.values())\n",
    "    top_writers = [writer_id for writer_id, _ in writers_counter.most_common(num_writers)]\n",
    "\n",
    "    # Create a temp directory containing only the selected sentences\n",
    "    temp_sentences_path = \"../data/temp_sentences\"\n",
    "    if not os.path.exists(temp_sentences_path):\n",
    "        os.makedirs(temp_sentences_path)\n",
    "\n",
    "    original_sentences_path = os.path.join(\"../data/sentences\", \"*\", \"*\", \"*.png\")\n",
    "\n",
    "    for file_path in glob.glob(original_sentences_path):\n",
    "        image_name = file_path.split(os.path.sep)[-1]\n",
    "        form_id = image_name.split('-')[0] + '-' + image_name.split('-')[1]\n",
    "\n",
    "        if form_id in top_forms:\n",
    "            try:\n",
    "                shutil.copy(file_path, os.path.join(temp_sentences_path, image_name))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to copy {file_path}. Error: {e}\")\n",
    "\n",
    "    # Create lists of file inputs (a form) and their respective targets (a writer id)\n",
    "    img_files = []\n",
    "    img_targets = []\n",
    "\n",
    "    path_to_files = os.path.join(temp_sentences_path, \"*\", \"*\", \"*.png\")\n",
    "    for file_path in glob.glob(path_to_files):\n",
    "        img_files.append(file_path)\n",
    "        img_targets.append(form_writer[file_path.split(os.path.sep)[-2]])\n",
    "\n",
    "    # Encode target values\n",
    "    encoder = LabelEncoder()\n",
    "    img_targets_encoded = encoder.fit_transform(img_targets)\n",
    "\n",
    "    # Normalize the pixel values and convert images to arrays\n",
    "    img_data = []\n",
    "    for img_path in img_files:\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img_data.append(np.array(img) / 255.0)\n",
    "\n",
    "    # Split the dataset into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(img_data, img_targets_encoded, test_size=0.2, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af4071",
   "metadata": {},
   "source": [
    "## Function to train the writer identification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0de1618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_writer_identification_model(X_train, y_train, X_val, y_val):\n",
    "    writer_identification_model = create_writer_identification_model()\n",
    "\n",
    "    # Define model checkpoint to save the best model\n",
    "    checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    # Train the model\n",
    "    history = writer_identification_model.fit(\n",
    "        generate_data(X_train, y_train, BATCH_SIZE, sample_ratio=0.5),\n",
    "        steps_per_epoch=len(X_train) / BATCH_SIZE,\n",
    "        validation_data=(X_val, to_categorical(y_val, NUM_LABELS)),\n",
    "        epochs=20,\n",
    "        callbacks=[checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return writer_identification_model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b703ccc",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55dee3f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_forms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Load and preprocess data\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     X_train, y_train, X_val, y_val, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Create and train the autoencoder\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     autoencoder \u001b[38;5;241m=\u001b[39m create_autoencoder()\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mload_and_preprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m image_name \u001b[38;5;241m=\u001b[39m file_path\u001b[38;5;241m.\u001b[39msplit(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     37\u001b[0m form_id \u001b[38;5;241m=\u001b[39m image_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m image_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m form_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtop_forms\u001b[49m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mcopy(file_path, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(temp_sentences_path, image_name))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_forms' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_and_preprocess_data()\n",
    "\n",
    "    # Create and train the autoencoder\n",
    "    autoencoder = create_autoencoder()\n",
    "    autoencoder.fit(X_train, X_train, epochs=10, batch_size=32)\n",
    "\n",
    "    # Extract features using the autoencoder\n",
    "    encoder_model = Model(inputs=autoencoder.input, outputs=autoencoder.layers[3].output)\n",
    "    X_train_features = extract_features(encoder_model, X_train)\n",
    "    X_val_features = extract_features(encoder_model, X_val)\n",
    "    X_test_features = extract_features(encoder_model, X_test)\n",
    "\n",
    "    # Train the writer identification model\n",
    "    writer_identification_model, history = train_writer_identification_model(X_train_features, y_train, X_val_features, y_val)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = writer_identification_model.evaluate(X_test_features, to_categorical(y_test, NUM_LABELS))\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
