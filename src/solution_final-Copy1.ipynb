{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zHuGCQFjN_l"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to store each form ID and its writer\n",
    "import os\n",
    "from itertools import islice\n",
    "\n",
    "form_writer = {}\n",
    "forms_file_path = \"../data/forms.txt\"\n",
    "with open(forms_file_path) as f:\n",
    "    for line in islice(f, 16, None):\n",
    "        line_list = line.split(' ')\n",
    "        form_id = line_list[0]\n",
    "        writer = line_list[1]\n",
    "        form_writer[form_id] = writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "FKJ6dsAGjN_q",
    "outputId": "cb98eba3-137f-4573-cd9f-6d172ba7d6cd"
   },
   "outputs": [],
   "source": [
    "list(form_writer.items())[0:5]\n",
    "print(\"Number of form-writer pairs:\", len(form_writer))\n",
    "print(list(form_writer.items())[0:5])\n",
    "print(\"Sample form-writer mappings:\", list(form_writer.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4le_mL3jN_t"
   },
   "outputs": [],
   "source": [
    "# Select the 50 most common writer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "top_writers = []\n",
    "num_writers = 50\n",
    "writers_counter = Counter(form_writer.values())\n",
    "for writer_id,_ in writers_counter.most_common(num_writers):\n",
    "    top_writers.append(writer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5mhwA0LrjN_x",
    "outputId": "7c141aa2-d171-499f-b1fd-738c182cdc83"
   },
   "outputs": [],
   "source": [
    "print(\"Top writer IDs:\", top_writers[0:5])\n",
    "print(top_writers[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MeRZBANbjN_0"
   },
   "outputs": [],
   "source": [
    "top_forms = []\n",
    "for form_id, author_id in form_writer.items():\n",
    "    if author_id in top_writers:\n",
    "        top_forms.append(form_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Uu5W_aXUjN_6",
    "outputId": "321e8045-0560-454a-80fe-479272f9f369"
   },
   "outputs": [],
   "source": [
    "print(\"Number of top forms:\", len(top_forms))\n",
    "print(\"Sample form IDs:\", top_forms[:5])\n",
    "print(top_forms[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQBL7IeajN__"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Create temp directory to save writers' forms in (assumes files have already been copied if the directory exists)\n",
    "temp_sentences_path = \"../data/temp_sentences\"\n",
    "if not os.path.exists(temp_sentences_path):\n",
    "    os.makedirs(temp_sentences_path)\n",
    "\n",
    "# Debugging Line 4: Check if 'top_forms' is correctly set\n",
    "#print(f\"Top Forms: {top_forms}\")\n",
    "\n",
    "original_sentences_path = os.path.join(\"..\", \"data\", \"sentences\", \"*\", \"*\", \"*.png\")\n",
    "\n",
    "# Debugging Line 5: Verify the Paths\n",
    "#print(\"Files found:\", glob.glob(original_sentences_path)[:5])\n",
    "\n",
    "for file_path in glob.glob(original_sentences_path):\n",
    "    image_name = file_path.split(os.path.sep)[-1]  # Use os.path.sep for cross-platform compatibility\n",
    "    form_id = image_name.split('-')[0] + '-' + image_name.split('-')[1]\n",
    "\n",
    "    if form_id in top_forms:\n",
    "        # Debugging Line 6: Check if Files are Copied\n",
    "        #print(f\"Copying file {file_path} to {temp_sentences_path}/{image_name}\")\n",
    "        try:\n",
    "            shutil.copy(file_path, os.path.join(temp_sentences_path, image_name))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to copy {file_path}. Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfzwf2BKjOAH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "img_files = np.zeros((0), dtype=str)\n",
    "img_targets = []\n",
    "\n",
    "path_to_files = os.path.join(temp_sentences_path, '*')\n",
    "for file_path in glob.glob(path_to_files):\n",
    "    img_files = np.append(img_files, file_path)\n",
    "    file_name, _ = os.path.splitext(file_path.split(os.path.sep)[-1])\n",
    "    form_id = '-'.join(file_name.split('-')[0:2])\n",
    "    if form_id in form_writer:\n",
    "        img_targets.append(form_writer[form_id])\n",
    "\n",
    "# Convert img_targets to a NumPy array\n",
    "img_targets = np.array(img_targets)\n",
    "\n",
    "# Debugging Line 7: Validate Array Populations\n",
    "print(\"Array lengths:\", len(img_files), len(img_targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "KI9InV7sjOAQ",
    "outputId": "42ad7fa7-b577-480a-c626-6cf0fe8b33f5"
   },
   "outputs": [],
   "source": [
    "print(f\"Checking path: {path_to_files}\")\n",
    "files_found = glob.glob(path_to_files)\n",
    "print(f\"Found {len(files_found)} files.\")\n",
    "\n",
    "print(img_files[0:5])\n",
    "print(img_targets[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "J1m2JtZyjOAT",
    "outputId": "65742ceb-8bbb-489a-846e-c07deaea435d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "for file_name in img_files[:2]:\n",
    "    img = mpimg.imread(file_name)\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.imshow(img, cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "y9A4WbqPjOAV",
    "outputId": "d1f8fcc5-8127-4231-b7cc-690c10dea186"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded_img_targets = encoder.fit_transform(img_targets)\n",
    "\n",
    "print(\"Writer ID        : \", img_targets[:2])\n",
    "print(\"Encoded writer ID: \", encoded_img_targets[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "SqFgVvjEjOAZ",
    "outputId": "5d069de7-a41a-4180-8106-42d213f4cd69"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_files, encoded_img_targets, test_size=0.2, shuffle = True)\n",
    "\n",
    "# Further split training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle = True)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UXwDegTjOAd"
   },
   "outputs": [],
   "source": [
    "CROP_SIZE = 113\n",
    "NUM_LABELS = 50\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckp7A0ZbjOAi"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "def get_augmented_sample(sample, label, sample_ratio):\n",
    "    # Get current image details\n",
    "    img = Image.open(sample)\n",
    "    img_width = img.size[0]\n",
    "    img_height = img.size[1]\n",
    "\n",
    "    # Compute resize dimensions such that aspect ratio is maintained\n",
    "    height_fac = CROP_SIZE / img_height\n",
    "    size = (int(img_width * height_fac), CROP_SIZE)\n",
    "\n",
    "    # Resize image \n",
    "    new_img = img.resize(size, Image.LANCZOS)\n",
    "    new_img_width = new_img.size[0]\n",
    "    new_img_height = new_img.size[1]\n",
    "\n",
    "    # Generate a random number of crops of size 113x113 from the resized image\n",
    "    x_coord = list(range(0, new_img_width - CROP_SIZE))\n",
    "    num_crops = int(len(x_coord) * sample_ratio)\n",
    "    random_x_coord = random.sample(x_coord, num_crops)\n",
    "    \n",
    "    # Create augmented images (cropped forms) and map them to a label (writer)\n",
    "    images = []\n",
    "    labels = []\n",
    "    for x in random_x_coord:\n",
    "        img_crop = new_img.crop((x, 0, x + CROP_SIZE, CROP_SIZE))\n",
    "        # Transform image to an array of numbers\n",
    "        images.append(np.asarray(img_crop))\n",
    "        labels.append(label)\n",
    "\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, label = X_train[0], y_train[0]\n",
    "img = mpimg.imread(sample)\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(img, cmap ='gray')\n",
    "print(\"Label: \", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = get_augmented_sample(sample, label, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)\n",
    "print(\"Num of labels: \", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images))\n",
    "plt.imshow(images[0], cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1], cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QpwonMROjOAm",
    "outputId": "66054b7c-046c-447d-c284-90ead6a2d4d0"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def generate_data(samples, labels, batch_size, sample_ratio):\n",
    "    while 1: \n",
    "        for offset in range(0, len(samples), batch_size):\n",
    "            batch_samples = samples[offset:(offset + batch_size)]\n",
    "            batch_labels = labels[offset:(offset + batch_size)]\n",
    "            \n",
    "            # Augment each sample in batch\n",
    "            augmented_batch_samples = []\n",
    "            augmented_batch_labels = []\n",
    "            for i in range(len(batch_samples)):\n",
    "                sample = batch_samples[i]\n",
    "                label = batch_labels[i]\n",
    "                augmented_samples, augmented_labels = get_augmented_sample(sample, label, sample_ratio)\n",
    "                augmented_batch_samples.append(augmented_samples)\n",
    "                augmented_batch_labels.append(augmented_labels)\n",
    "\n",
    "            # Flatten out samples and labels\n",
    "            augmented_batch_samples = reduce(operator.add, augmented_batch_samples)\n",
    "            augmented_batch_labels = reduce(operator.add, augmented_batch_labels)\n",
    "            \n",
    "            # Reshape input format\n",
    "            X_train = np.array(augmented_batch_samples)\n",
    "            X_train = X_train.reshape(X_train.shape[0], CROP_SIZE, CROP_SIZE, 1)\n",
    "\n",
    "            # Transform input to float and normalize\n",
    "            X_train = X_train.astype('float32')\n",
    "            X_train /= 255\n",
    "\n",
    "            # Encode y\n",
    "            y_train = np.array(augmented_batch_labels)\n",
    "            y_train = to_categorical(y_train, NUM_LABELS)\n",
    "\n",
    "            yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9dr2pogjOAp"
   },
   "outputs": [],
   "source": [
    "train_generator = generate_data(X_train, y_train, BATCH_SIZE, 0.3)\n",
    "validation_generator = generate_data(X_val, y_val, BATCH_SIZE, 0.3)\n",
    "test_generator = generate_data(X_test, y_test, BATCH_SIZE, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KeHK6NkTjOAr",
    "outputId": "cccba7d3-41fe-4924-8259-57d209c216d9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fvu-0oV4jOAu"
   },
   "outputs": [],
   "source": [
    "def resize_image(img):\n",
    "    size = round(CROP_SIZE/2)\n",
    "    return tf.image.resize(img, [size, size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "mR01wBGijOAx",
    "outputId": "b8f4c4d1-6599-4569-d08e-2d48a060f47a"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras import metrics\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Define network input shape\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(CROP_SIZE, CROP_SIZE, 1)))\n",
    "# Resize images to allow for easy computation\n",
    "model.add(Lambda(resize_image))\n",
    "\n",
    "# CNN model - Building the model suggested in paper\n",
    "model.add(Convolution2D(filters= 32, kernel_size =(5,5), strides= (2, 2), padding='same', name='conv1'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1'))\n",
    "\n",
    "model.add(Convolution2D(filters= 64, kernel_size =(3, 3), strides= (1, 1), padding='same', name='conv2'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool2'))\n",
    "\n",
    "model.add(Convolution2D(filters= 128, kernel_size =(3, 3), strides= (1, 1), padding='same', name='conv3'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool3'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, name='dense1'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, name='dense2'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(NUM_LABELS, name='output'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['acc'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1397
    },
    "colab_type": "code",
    "id": "AWcVj_1WjOAy",
    "outputId": "5fb3ea7c-b304-40f3-ad21-ab2b06aad5a1"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "\n",
    "# Create directory to save checkpoints at\n",
    "model_checkpoints_path = \"./model_checkpoints\"\n",
    "if not os.path.exists(model_checkpoints_path):\n",
    "    os.makedirs(model_checkpoints_path)\n",
    "\n",
    "# Save model after every epoch using checkpoints\n",
    "create_checkpoint = ModelCheckpoint(\n",
    "    filepath=\"./model_checkpoints/check_{epoch:02d}_{val_loss:.4f}.hdf5\",\n",
    "    verbose=1,\n",
    "    save_best_only=False\n",
    ")\n",
    "\n",
    "# Early stopping to stop the training if the validation loss does not improve for 5 epochs\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Fit model using generators\n",
    "history_object = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=round(len(X_train) / BATCH_SIZE),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=round(len(X_val) / BATCH_SIZE),\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    callbacks=[create_checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the model's weights\n",
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = \"./my_model_weights.h5\"\n",
    "if model_weights_path:\n",
    "    model.load_weights(model_weights_path)\n",
    "    scores = model.evaluate(test_generator, steps=round(len(X_test)/BATCH_SIZE))\n",
    "    print(\"Accuracy: \", scores[1])\n",
    "else:\n",
    "    print(\"Set model weights file to load in the 'model_weights_path' variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Path to the saved entire model\n",
    "model_path = \"./my_model.h5\"\n",
    "\n",
    "if model_path:\n",
    "    # Load the entire saved model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Evaluate the model using the test generator\n",
    "    scores = model.evaluate(test_generator, steps=round(len(X_test)/BATCH_SIZE))\n",
    "    \n",
    "    print(\"Accuracy: \", scores[1])\n",
    "else:\n",
    "    print(\"Set model file to load in the 'model_path' variable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_data_generator(samples, batch_size):\n",
    "    while 1: \n",
    "        for offset in range(0, len(samples), batch_size):\n",
    "            batch_samples = samples[offset:offset + batch_size]\n",
    "            \n",
    "            images = []\n",
    "            for sample in batch_samples:\n",
    "                img = Image.open(sample)\n",
    "                img = img.resize((113, 113))  # Resize to your input size\n",
    "                img_array = np.asarray(img)\n",
    "                images.append(img_array)\n",
    "            \n",
    "            X_train = np.array(images)\n",
    "            X_train = X_train.reshape(X_train.shape[0], 113, 113, 1)\n",
    "            X_train = X_train.astype('float32')\n",
    "            X_train /= 255\n",
    "            \n",
    "            yield X_train, X_train  # x and y are the same for an autoencoder\n",
    "\n",
    "# Create autoencoder data generators\n",
    "autoencoder_train_generator = autoencoder_data_generator(X_train, 16)\n",
    "autoencoder_val_generator = autoencoder_data_generator(X_val, 16)\n",
    "\n",
    "# Now you can use these in your autoencoder training:\n",
    "autoencoder.fit(autoencoder_train_generator, epochs=50, \n",
    "                steps_per_epoch=len(X_train) // 16,\n",
    "                validation_data=autoencoder_val_generator,\n",
    "                validation_steps=len(X_val) // 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "# Assuming each image has a shape of (113, 113, 1)\n",
    "input_shape = (113, 113, 1)\n",
    "encoding_dim = 64  # size of the encoded representations\n",
    "\n",
    "# Encoder\n",
    "input_img = Input(shape=input_shape)\n",
    "flattened = Flatten()(input_img)\n",
    "encoded = Dense(encoding_dim, activation='relu')(flattened)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(np.prod(input_shape), activation='sigmoid')(encoded)\n",
    "decoded = Reshape(input_shape)(decoded)\n",
    "\n",
    "# Full autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# You may need to adjust your data generators to work with the autoencoder.\n",
    "# For now, I'm assuming you have suitable `autoencoder_train_generator` and `autoencoder_val_generator`.\n",
    "autoencoder.fit(autoencoder_train_generator, epochs=50, \n",
    "                steps_per_epoch=len(X_train) // 16,\n",
    "                validation_data=autoencoder_val_generator,\n",
    "                validation_steps=len(X_val) // 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model for feature extraction\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "writer_centroids = defaultdict(list)\n",
    "\n",
    "# Loop through each writer's images\n",
    "for writer_id in top_writers:  # Assuming top_writers contains the writer IDs\n",
    "    writer_images = []  # Collect all images for this writer\n",
    "    for form_id, writer in form_writer.items():\n",
    "        if writer == writer_id:\n",
    "            image_path = os.path.join(temp_sentences_path, form_id + '.png')  # Adjust as needed\n",
    "            image = Image.open(\"../data/a01-043u-s04-03.png\")\n",
    "            image = image.resize((113, 113))\n",
    "            writer_images.append(np.asarray(image))\n",
    "            \n",
    "    writer_images = np.array(writer_images).reshape(len(writer_images), 113, 113, 1)\n",
    "    encoded_images = encoder.predict(writer_images)\n",
    "    centroid = np.mean(encoded_images, axis=0)\n",
    "    writer_centroids[writer_id] = centroid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_thresholds = {}\n",
    "\n",
    "for writer_id, centroid in writer_centroids.items():\n",
    "    writer_images = []  # Collect all images for this writer\n",
    "    for form_id, writer in form_writer.items():\n",
    "        if writer == writer_id:\n",
    "            image_path = os.path.join(temp_sentences_path, form_id + '.png')  # Adjust as needed\n",
    "            image = Image.open(\"../data/a01-043u-s04-03.png\")\n",
    "            image = image.resize((113, 113))\n",
    "            writer_images.append(np.asarray(image))\n",
    "            \n",
    "    writer_images = np.array(writer_images).reshape(len(writer_images), 113, 113, 1)\n",
    "    encoded_images = encoder.predict(writer_images)\n",
    "    distances = [np.linalg.norm(encoded - centroid) for encoded in encoded_images]\n",
    "    avg_distance = np.mean(distances)\n",
    "    writer_thresholds[writer_id] = avg_distance * 1.2  # Adding some margin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_writer(new_image, writer_centroids, writer_thresholds):\n",
    "    # Preprocess the new image and encode it\n",
    "    new_image = Image.open(new_image).resize((113, 113))\n",
    "    new_image = np.asarray(new_image).reshape(1, 113, 113, 1)\n",
    "    encoded_image = encoder.predict(new_image)\n",
    "\n",
    "    for writer_id, centroid in writer_centroids.items():\n",
    "        distance = np.linalg.norm(encoded_image - centroid)\n",
    "        if distance < writer_thresholds[writer_id]:\n",
    "            print(f\"Writer identified as {writer_id}\")\n",
    "            return writer_id\n",
    "\n",
    "    print(\"This is a new writer.\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection for New Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have some 'normal_data_points' and one 'new_data_point'\n",
    "normal_data_points = np.random.rand(100, 113, 113, 1)  # Replace with your actual normal data\n",
    "new_data_point = np.random.rand(1, 113, 113, 1)  # Replace with your actual new data point\n",
    "\n",
    "# Encode the normal data points to get their latent space representations\n",
    "encoded_normal_data_points = encoder.predict(normal_data_points)\n",
    "\n",
    "# Encode the new data point to get its latent space representation\n",
    "encoded_new_data_point = encoder.predict(new_data_point)\n",
    "\n",
    "# Calculate the centroid of the normal data points in the latent space\n",
    "centroid = np.mean(encoded_normal_data_points, axis=0)\n",
    "\n",
    "# Calculate the distance between the new data point and the centroid\n",
    "distance = np.linalg.norm(encoded_new_data_point - centroid)\n",
    "\n",
    "# Define a threshold for anomaly detection (this should be based on your specific case)\n",
    "threshold = 10.0\n",
    "\n",
    "# Detect if the new data point is an anomaly\n",
    "if distance > threshold:\n",
    "    print(\"Anomaly detected\")\n",
    "else:\n",
    "    print(\"No anomaly detected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Read the image\n",
    "img_path = 'path/to/your/test/image.png'  # Replace with the actual path\n",
    "img = Image.open(img_path)\n",
    "\n",
    "# Step 2: Resize and preprocess\n",
    "img = img.resize((CROP_SIZE, CROP_SIZE))  # Replace CROP_SIZE with the actual size\n",
    "img_array = np.asarray(img)\n",
    "\n",
    "# Step 3: Expand dimensions to match the input shape\n",
    "test_data_point = np.expand_dims(img_array, axis=0)  # Makes it (1, CROP_SIZE, CROP_SIZE, num_channels)\n",
    "\n",
    "# If your images are grayscale and your model expects a single channel image, you might also need to reshape:\n",
    "test_data_point = test_data_point.reshape(test_data_point.shape[0], CROP_SIZE, CROP_SIZE, 1)\n",
    "\n",
    "# Normalize the data if your model expects that\n",
    "test_data_point = test_data_point.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate with Original Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming original_model and test_data_point are defined and preprocessed\n",
    "# Define your confidence_threshold\n",
    "original_model = model\n",
    "confidence_threshold = 0.8\n",
    "\n",
    "# Make a prediction with the original classifier\n",
    "original_prediction = original_model.predict(test_data_point)\n",
    "\n",
    "# If prediction confidence is low, check for the new class\n",
    "if max(original_prediction[0]) < confidence_threshold:\n",
    "    # Encode the test data point to get its latent space representation\n",
    "    encoded_test_data_point = encoder.predict(test_data_point)\n",
    "    \n",
    "    # Calculate the 'difference' based on your specific logic\n",
    "    # For instance, using Euclidean distance from a centroid\n",
    "    difference = np.linalg.norm(encoded_test_data_point - centroid)\n",
    "    \n",
    "    # Define your 'threshold' for anomaly detection\n",
    "    threshold = 10.0  # Replace with your actual threshold\n",
    "    \n",
    "    # Measure the difference and check against the threshold\n",
    "    if difference > threshold:\n",
    "        final_prediction = \"new_class\"\n",
    "    else:\n",
    "        final_prediction = np.argmax(original_prediction)  # or any other way to interpret the prediction\n",
    "else:\n",
    "    final_prediction = np.argmax(original_prediction)  # or any other way to interpret the prediction\n",
    "\n",
    "print(\"Final Prediction:\", final_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "solution.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
