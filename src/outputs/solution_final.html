<!DOCTYPE html>
<html>
<head>
<title>solution_final.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="iam-writer-recognition">IAM Writer Recognition</h1>
<p>This notebook is pretty much a translation of the &quot;<a href="https://github.com/priya-dwivedi/Deep-Learning/tree/master/handwriting_recognition">handwriting_recognition</a>&quot; notebook by <a href="https://github.com/priya-dwivedi">Priyanka Dwivedi</a>. I have chosen to rewrite it differently here as to make it easier to follow, for my own better understanding, and for others who wish to learn from it.</p>
<p>The goal of the notebook is to use the method explained in the paper <a href="https://arxiv.org/abs/1606.06472">DeepWriter: A Multi-Stream Deep CNN for Text-independent Writer Identification</a> to identify the writer (author) of a text based on their writing styles. To do so, we'll use the <a href="http://www.fki.inf.unibe.ch/databases/iam-handwriting-database/download-the-iam-handwriting-database">IAM Handwriting Database</a>. Please make sure the dataset has been correctly set up before executing the notebook as outlined <a href="https://github.com/diegocasmo/iam_writer_recognition/tree/master/data">here</a>.</p>
<h1 id="reading-the-dataset">Reading The Dataset</h1>
<p>The first step is to create a dictionary which will map each form ID (sentence) to a writer. This information is available in the <code>forms.txt</code> file, where each line (except for the first 16 lines, which are documentation) defines the form ID at index <code>0</code>, and its writer at index <code>1</code>.</p>
<pre class="hljs"><code><div><span class="hljs-comment"># Create a dictionary to store each form ID and its writer</span>
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> islice

form_writer = {}
forms_file_path = <span class="hljs-string">"../data/forms.txt"</span>
<span class="hljs-keyword">with</span> open(forms_file_path) <span class="hljs-keyword">as</span> f:
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> islice(f, <span class="hljs-number">16</span>, <span class="hljs-literal">None</span>):
        line_list = line.split(<span class="hljs-string">' '</span>)
        form_id = line_list[<span class="hljs-number">0</span>]
        writer = line_list[<span class="hljs-number">1</span>]
        form_writer[form_id] = writer
</div></code></pre>
<p>Visualize dictionary (as array for simplicity):</p>
<pre class="hljs"><code><div>list(form_writer.items())[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>]
print(<span class="hljs-string">"Number of form-writer pairs:"</span>, len(form_writer))
print(list(form_writer.items())[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>])
print(<span class="hljs-string">"Sample form-writer mappings:"</span>, list(form_writer.items())[:<span class="hljs-number">5</span>])
</div></code></pre>
<pre><code>Number of form-writer pairs: 1539
[('a01-000u', '000'), ('a01-000x', '001'), ('a01-003', '002'), ('a01-003u', '000'), ('a01-003x', '003')]
Sample form-writer mappings: [('a01-000u', '000'), ('a01-000x', '001'), ('a01-003', '002'), ('a01-003u', '000'), ('a01-003x', '003')]
</code></pre>
<p>For efficiency reasons,  we'll select the 50 most common writers from the dictionary we have created, and the rest of the notebook will only focus on them (as opposed to using the 221 authors present in the dataset).</p>
<pre class="hljs"><code><div><span class="hljs-comment"># Select the 50 most common writer</span>

<span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter

top_writers = []
num_writers = <span class="hljs-number">50</span>
writers_counter = Counter(form_writer.values())
<span class="hljs-keyword">for</span> writer_id,_ <span class="hljs-keyword">in</span> writers_counter.most_common(num_writers):
    top_writers.append(writer_id)
</div></code></pre>
<p>Visualize the writer id of the top 50 writers:</p>
<pre class="hljs"><code><div>print(<span class="hljs-string">"Top writer IDs:"</span>, top_writers[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>])
print(top_writers[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>])
</div></code></pre>
<pre><code>Top writer IDs: ['000', '150', '151', '152', '153']
['000', '150', '151', '152', '153']
</code></pre>
<p>From the 50 most common writers we have selected, we'll now need to select the forms (sentences) they have written:</p>
<pre class="hljs"><code><div>top_forms = []
<span class="hljs-keyword">for</span> form_id, author_id <span class="hljs-keyword">in</span> form_writer.items():
    <span class="hljs-keyword">if</span> author_id <span class="hljs-keyword">in</span> top_writers:
        top_forms.append(form_id)
</div></code></pre>
<p>Visualize the form id of the top 50 writers:</p>
<pre class="hljs"><code><div>print(<span class="hljs-string">"Number of top forms:"</span>, len(top_forms))
print(<span class="hljs-string">"Sample form IDs:"</span>, top_forms[:<span class="hljs-number">5</span>])
print(top_forms[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>])
</div></code></pre>
<pre><code>Number of top forms: 452
Sample form IDs: ['a01-000u', 'a01-003u', 'a01-007u', 'a01-011u', 'a01-014u']
['a01-000u', 'a01-003u', 'a01-007u', 'a01-011u', 'a01-014u']
</code></pre>
<p>Create a temp directory which contains only the sentences of the forms selected above:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> glob
<span class="hljs-keyword">import</span> shutil

<span class="hljs-comment"># Create temp directory to save writers' forms in (assumes files have already been copied if the directory exists)</span>
temp_sentences_path = <span class="hljs-string">"../data/temp_sentences"</span>
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(temp_sentences_path):
    os.makedirs(temp_sentences_path)

<span class="hljs-comment"># Debugging Line 4: Check if 'top_forms' is correctly set</span>
print(<span class="hljs-string">f"Top Forms: <span class="hljs-subst">{top_forms}</span>"</span>)

original_sentences_path = os.path.join(<span class="hljs-string">".."</span>, <span class="hljs-string">"data"</span>, <span class="hljs-string">"sentences"</span>, <span class="hljs-string">"*"</span>, <span class="hljs-string">"*"</span>, <span class="hljs-string">"*.png"</span>)

<span class="hljs-comment"># Debugging Line 5: Verify the Paths</span>
print(<span class="hljs-string">"Files found:"</span>, glob.glob(original_sentences_path)[:<span class="hljs-number">5</span>])

<span class="hljs-keyword">for</span> file_path <span class="hljs-keyword">in</span> glob.glob(original_sentences_path):
    image_name = file_path.split(os.path.sep)[<span class="hljs-number">-1</span>]  <span class="hljs-comment"># Use os.path.sep for cross-platform compatibility</span>
    form_id = image_name.split(<span class="hljs-string">'-'</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">'-'</span> + image_name.split(<span class="hljs-string">'-'</span>)[<span class="hljs-number">1</span>]

    <span class="hljs-keyword">if</span> form_id <span class="hljs-keyword">in</span> top_forms:
        <span class="hljs-comment"># Debugging Line 6: Check if Files are Copied</span>
        print(<span class="hljs-string">f"Copying file <span class="hljs-subst">{file_path}</span> to <span class="hljs-subst">{temp_sentences_path}</span>/<span class="hljs-subst">{image_name}</span>"</span>)
        <span class="hljs-keyword">try</span>:
            shutil.copy(file_path, os.path.join(temp_sentences_path, image_name))
        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
            print(<span class="hljs-string">f"Failed to copy <span class="hljs-subst">{file_path}</span>. Error: <span class="hljs-subst">{e}</span>"</span>)

</div></code></pre>
<pre><code>Top Forms: ['a01-000u', 'a01-003u', 'a01-007u', 'a01-011u', 'a01-014u', 'a01-020u', 'a01-026u', 'a01-030u', 'a01-043u', 'a01-049u', 'a01-049x', 'a01-053u', 'a01-058u', 'a01-063u', 'a01-068u', 'a01-072u', 'a01-077u', 'a01-082u', 'a01-087u', 'a01-091u', 'a01-096u', 'a01-102u', 'a01-107u', 'a01-113u', 'a01-117u', 'a01-122u', 'a01-128u', 'a01-132u', 'a01-132x', 'a02-017', 'a02-020', 'a02-024', 'a02-027', 'a02-032', 'a02-037', 'a02-042', 'a02-090', 'a02-093', 'a02-098', 'a02-102', 'a02-106', 'a02-111', 'a02-124', 'a03-047', 'a03-050', 'a03-071', 'a03-073', 'a03-080', 'a03-089', 'a05-000', 'a05-013', 'a05-017', 'a05-022', 'a05-025', 'a05-029', 'a05-039', 'a05-044', 'a05-048', 'a05-053', 'a05-058', 'a05-062', 'a05-069', 'a05-073', 'a05-080', 'a05-084', 'a05-089', 'a05-094', 'a05-099', 'a05-104', 'a05-108', 'a05-113', 'a05-116', 'a05-121', 'a05-125', 'a06-124', 'a06-134', 'a06-141', 'a06-147', 'a06-157', 'b05-055', 'b05-058', 'b05-062', 'b05-067', 'b05-071', 'b06-000', 'b06-008', 'b06-012', 'b06-019', 'b06-023', 'b06-032', 'b06-036', 'b06-056', 'b06-059', 'b06-064', 'b06-071', 'b06-079', 'b06-093', 'b06-097', 'b06-100', 'b06-110', 'c03-000a', 'c03-000b', 'c03-000c', 'c03-000d', 'c03-000e', 'c03-000f', 'c03-003a', 'c03-003b', 'c03-003c', 'c03-003d', 'c03-003e', 'c03-003f', 'c03-007a', 'c03-007b', 'c03-007c', 'c03-007d', 'c03-007e', 'c03-007f', 'c03-016a', 'c03-016b', 'c03-016c', 'c03-016d', 'c03-016e', 'c03-021a', 'c03-021b', 'c03-021c', 'c03-021d', 'c03-021e', 'c03-021f', 'c03-081a', 'c03-081b', 'c03-081c', 'c03-081d', 'c03-081e', 'c03-081f', 'c03-084a', 'c03-084b', 'c03-084c', 'c03-084d', 'c03-084e', 'c03-084f', 'c03-087a', 'c03-087b', 'c03-087c', 'c03-087d', 'c03-087e', 'c03-087f', 'c03-094a', 'c03-094b', 'c03-094c', 'c03-094d', 'c03-094e', 'c03-094f', 'c03-096a', 'c03-096b', 'c03-096c', 'c03-096d', 'c03-096e', 'c03-096f', 'c06-000', 'c06-005', 'c06-011', 'c06-020', 'c06-027', 'c06-031', 'c06-039', 'c06-043', 'c06-052', 'c06-076', 'c06-080', 'c06-083', 'c06-087', 'c06-100', 'c06-116', 'c06-128', 'd06-008', 'd06-015', 'd06-020', 'd06-030', 'd06-046', 'd06-050', 'd06-063', 'd06-082', 'd07-082', 'd07-085', 'd07-089', 'd07-093', 'd07-096', 'd07-100', 'd07-102', 'e07-000', 'g03-049', 'g05-098', 'g06-011a', 'g06-011b', 'g06-011c', 'g06-011e', 'g06-011f', 'g06-011g', 'g06-011h', 'g06-011i', 'g06-011j', 'g06-011k', 'g06-011l', 'g06-011m', 'g06-011n', 'g06-011o', 'g06-011p', 'g06-011r', 'g06-018a', 'g06-018b', 'g06-018c', 'g06-018d', 'g06-018e', 'g06-018f', 'g06-018g', 'g06-018h', 'g06-018i', 'g06-018j', 'g06-018k', 'g06-018l', 'g06-018m', 'g06-018n', 'g06-018o', 'g06-018p', 'g06-018r', 'g06-026a', 'g06-026b', 'g06-026c', 'g06-026d', 'g06-026e', 'g06-026f', 'g06-026g', 'g06-026h', 'g06-026i', 'g06-026j', 'g06-026k', 'g06-026l', 'g06-026m', 'g06-026n', 'g06-026o', 'g06-026p', 'g06-026r', 'g06-031a', 'g06-031b', 'g06-031c', 'g06-031d', 'g06-031e', 'g06-031f', 'g06-031g', 'g06-031h', 'g06-031i', 'g06-031j', 'g06-031k', 'g06-031l', 'g06-031m', 'g06-031n', 'g06-031o', 'g06-031p', 'g06-031r', 'g06-037b', 'g06-037c', 'g06-037d', 'g06-037e', 'g06-037f', 'g06-037g', 'g06-037h', 'g06-037i', 'g06-037j', 'g06-037k', 'g06-037l', 'g06-037m', 'g06-037n', 'g06-037o', 'g06-037p', 'g06-037r', 'g06-042a', 'g06-042b', 'g06-042c', 'g06-042d', 'g06-042e', 'g06-042f', 'g06-042g', 'g06-042h', 'g06-042i', 'g06-042j', 'g06-042k', 'g06-042l', 'g06-042m', 'g06-042n', 'g06-042o', 'g06-042p', 'g06-042r', 'g06-045a', 'g06-045b', 'g06-045c', 'g06-045d', 'g06-045e', 'g06-045f', 'g06-045g', 'g06-045h', 'g06-045i', 'g06-045j', 'g06-045k', 'g06-045l', 'g06-045m', 'g06-045n', 'g06-045o', 'g06-045p', 'g06-045r', 'g06-047a', 'g06-047b', 'g06-047c', 'g06-047d', 'g06-047e', 'g06-047f', 'g06-047g', 'g06-047h', 'g06-047i', 'g06-047j', 'g06-047k', 'g06-047l', 'g06-047m', 'g06-047n', 'g06-047o', 'g06-047p', 'g06-047r', 'g06-050a', 'g06-050b', 'g06-050c', 'g06-050d', 'g06-050e', 'g06-050f', 'g06-050g', 'g06-050h', 'g06-050i', 'g06-050j', 'g06-050k', 'g06-050l', 'g06-050m', 'g06-050n', 'g06-050o', 'g06-050p', 'g06-050r', 'g06-089', 'g06-093', 'g06-096', 'g06-101', 'g06-105', 'g06-109', 'g06-115', 'h05-012', 'h06-000', 'h06-003', 'h06-079', 'h06-082', 'h06-085', 'h06-089', 'h06-092', 'h06-096', 'j06-000', 'j06-005', 'j06-008', 'j06-014', 'j06-018', 'j06-022', 'j06-026', 'j06-030', 'j06-034', 'j06-051', 'j06-056', 'm06-019', 'm06-031', 'm06-042', 'm06-048', 'm06-056', 'm06-067', 'm06-076', 'm06-083', 'm06-091', 'm06-098', 'm06-106', 'n02-098', 'n02-104', 'n02-109', 'n02-114', 'n02-120', 'n02-127', 'n06-074', 'n06-082', 'n06-092', 'n06-100', 'n06-111', 'n06-119', 'n06-123', 'n06-128', 'n06-133', 'n06-140', 'n06-148', 'n06-156', 'n06-163', 'n06-169', 'n06-175', 'n06-182', 'n06-186', 'n06-194', 'n06-201', 'p03-057', 'p03-087', 'p03-096', 'p03-103', 'p03-112', 'p06-030', 'p06-042', 'p06-047', 'p06-052', 'p06-058', 'p06-069', 'p06-088', 'p06-096', 'p06-104', 'p06-242', 'p06-248', 'r03-053', 'r06-000', 'r06-003', 'r06-007', 'r06-011', 'r06-018', 'r06-022', 'r06-027', 'r06-035', 'r06-041', 'r06-044', 'r06-049', 'r06-053', 'r06-057', 'r06-062', 'r06-066', 'r06-070', 'r06-076', 'r06-090', 'r06-097', 'r06-103', 'r06-106', 'r06-111', 'r06-115', 'r06-121', 'r06-126', 'r06-130', 'r06-137', 'r06-143']
Files found: ['..\\data\\sentences\\a01\\a01-000u\\a01-000u-s00-00.png', '..\\data\\sentences\\a01\\a01-000u\\a01-000u-s00-01.png', '..\\data\\sentences\\a01\\a01-000u\\a01-000u-s00-02.png', '..\\data\\sentences\\a01\\a01-000u\\a01-000u-s00-03.png', '..\\data\\sentences\\a01\\a01-000u\\a01-000u-s01-00.png']
Copying file ..\data\sentences\a01\a01-000u\a01-000u-s00-00.png to ../data/temp_sentences/a01-000u-s00-00.png
Copying file ..\data\sentences\a01\a01-000u\a01-000u-s00-01.png to ../data/temp_sentences/a01-000u-s00-01.png
Copying file ..\data\sentences\a01\a01-000u\a01-000u-s00-02.png to ../data/temp_sentences/a01-000u-s00-02.png
Copying file ..\data\sentences\r06\r06-143\r06-143-s03-00.png to ../data/temp_sentences/r06-143-s03-00.png
Copying file ..\data\sentences\r06\r06-143\r06-143-s04-00.png to ../data/temp_sentences/r06-143-s04-00.png
Copying file ..\data\sentences\r06\r06-143\r06-143-s04-01.png to ../data/temp_sentences/r06-143-s04-01.png
</code></pre>
<p>Create arrays of file inputs (a form) and their respective targets (a writer id):</p>
<pre class="hljs"><code><div><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> glob
<span class="hljs-keyword">import</span> shutil
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

img_files = np.zeros((<span class="hljs-number">0</span>), dtype=str)
img_targets = []

path_to_files = os.path.join(temp_sentences_path, <span class="hljs-string">'*'</span>)
<span class="hljs-keyword">for</span> file_path <span class="hljs-keyword">in</span> glob.glob(path_to_files):
    img_files = np.append(img_files, file_path)
    file_name, _ = os.path.splitext(file_path.split(os.path.sep)[<span class="hljs-number">-1</span>])
    form_id = <span class="hljs-string">'-'</span>.join(file_name.split(<span class="hljs-string">'-'</span>)[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>])
    <span class="hljs-keyword">if</span> form_id <span class="hljs-keyword">in</span> form_writer:
        img_targets.append(form_writer[form_id])

<span class="hljs-comment"># Convert img_targets to a NumPy array</span>
img_targets = np.array(img_targets)

<span class="hljs-comment"># Debugging Line 7: Validate Array Populations</span>
print(<span class="hljs-string">"Array lengths:"</span>, len(img_files), len(img_targets))

</div></code></pre>
<pre><code>Array lengths: 4909 4909
</code></pre>
<p>Visualize the form -&gt; writer id arrays:</p>
<pre class="hljs"><code><div>print(<span class="hljs-string">f"Checking path: <span class="hljs-subst">{path_to_files}</span>"</span>)
files_found = glob.glob(path_to_files)
print(<span class="hljs-string">f"Found <span class="hljs-subst">{len(files_found)}</span> files."</span>)

print(img_files[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>])
print(img_targets[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>])
</div></code></pre>
<pre><code>Checking path: ../data/temp_sentences\*
Found 4909 files.
['../data/temp_sentences\\a01-000u-s00-00.png'
 '../data/temp_sentences\\a01-000u-s00-01.png'
 '../data/temp_sentences\\a01-000u-s00-02.png'
 '../data/temp_sentences\\a01-000u-s00-03.png'
 '../data/temp_sentences\\a01-000u-s01-00.png']
['000' '000' '000' '000' '000']
</code></pre>
<p>Visualize dataset's images:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> matplotlib.image <span class="hljs-keyword">as</span> mpimg
%matplotlib inline

<span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> img_files[:<span class="hljs-number">2</span>]:
    img = mpimg.imread(file_name)
    plt.figure(figsize = (<span class="hljs-number">10</span>,<span class="hljs-number">10</span>))
    plt.imshow(img, cmap =<span class="hljs-string">'gray'</span>)
</div></code></pre>
<p><img src="solution_final_files/solution_final_23_0.png" alt="png"></p>
<p><img src="solution_final_files/solution_final_23_1.png" alt="png"></p>
<p>Encode writers with a value between 0 and <code>n_classes-1</code>:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelEncoder

encoder = LabelEncoder()
encoded_img_targets = encoder.fit_transform(img_targets)

print(<span class="hljs-string">"Writer ID        : "</span>, img_targets[:<span class="hljs-number">2</span>])
print(<span class="hljs-string">"Encoded writer ID: "</span>, encoded_img_targets[:<span class="hljs-number">2</span>])
</div></code></pre>
<pre><code>Writer ID        :  ['000' '000']
Encoded writer ID:  [0 0]
</code></pre>
<p>Split dataset into train, validation, and tests sets:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split

<span class="hljs-comment"># Split dataset into training and test sets</span>
X_train, X_test, y_train, y_test = train_test_split(img_files, encoded_img_targets, test_size=<span class="hljs-number">0.2</span>, shuffle = <span class="hljs-literal">True</span>)

<span class="hljs-comment"># Further split training set into training and validation sets</span>
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=<span class="hljs-number">0.2</span>, shuffle = <span class="hljs-literal">True</span>)

print(X_train.shape, X_val.shape, X_test.shape)
print(y_train.shape, y_val.shape, y_test.shape)
</div></code></pre>
<pre><code>(3141,) (786,) (982,)
(3141,) (786,) (982,)
</code></pre>
<p>Define a couple of constants that will be used throughout the model:</p>
<pre class="hljs"><code><div>CROP_SIZE = <span class="hljs-number">113</span>
NUM_LABELS = <span class="hljs-number">50</span>
BATCH_SIZE = <span class="hljs-number">16</span>
</div></code></pre>
<p>As suggested in the paper, the input to the model are not unique sentences but rather random patches cropped from each sentence. The <code>get_augmented_sample</code> method is in charge of doing so by resizing each sentence's height to <code>113</code> pixels, and its width such that original aspect ratio is maintained. Finally, from the resized image, patches of <code>113x113</code> are randomly cropped.</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> sklearn.utils <span class="hljs-keyword">import</span> shuffle
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">import</span> random

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_augmented_sample</span><span class="hljs-params">(sample, label, sample_ratio)</span>:</span>
    <span class="hljs-comment"># Get current image details</span>
    img = Image.open(sample)
    img_width = img.size[<span class="hljs-number">0</span>]
    img_height = img.size[<span class="hljs-number">1</span>]

    <span class="hljs-comment"># Compute resize dimensions such that aspect ratio is maintained</span>
    height_fac = CROP_SIZE / img_height
    size = (int(img_width * height_fac), CROP_SIZE)

    <span class="hljs-comment"># Resize image </span>
    new_img = img.resize((size), Image.ANTIALIAS)
    new_img_width = new_img.size[<span class="hljs-number">0</span>]
    new_img_height = new_img.size[<span class="hljs-number">1</span>]

    <span class="hljs-comment"># Generate a random number of crops of size 113x113 from the resized image</span>
    x_coord = list(range(<span class="hljs-number">0</span>, new_img_width - CROP_SIZE))
    num_crops = int(len(x_coord) * sample_ratio)
    random_x_coord = random.sample(x_coord, num_crops)
    
    <span class="hljs-comment"># Create augmented images (cropped forms) and map them to a label (writer)</span>
    images = []
    labels = []
    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> random_x_coord:
        img_crop = new_img.crop((x, <span class="hljs-number">0</span>, x + CROP_SIZE, CROP_SIZE))
        <span class="hljs-comment"># Transform image to an array of numbers</span>
        images.append(np.asarray(img_crop))
        labels.append(label)

    <span class="hljs-keyword">return</span> (images, labels)
</div></code></pre>
<p>Let's visualize what the <code>get_augmented_sample</code> method does by augmenting one sample from the training set. Let's first take a look at how the original image looks like:</p>
<pre class="hljs"><code><div>sample, label = X_train[<span class="hljs-number">0</span>], y_train[<span class="hljs-number">0</span>]
img = mpimg.imread(sample)
plt.figure(figsize = (<span class="hljs-number">10</span>,<span class="hljs-number">10</span>))
plt.imshow(img, cmap =<span class="hljs-string">'gray'</span>)
print(<span class="hljs-string">"Label: "</span>, label)
</div></code></pre>
<pre><code>Label:  21
</code></pre>
<p><img src="solution_final_files/solution_final_33_1.png" alt="png"></p>
<p>A now, let's augment it and see the result:</p>
<pre class="hljs"><code><div>images, labels = get_augmented_sample(sample, label, <span class="hljs-number">0.1</span>)
</div></code></pre>
<pre><code>C:\Users\User\AppData\Local\Temp\ipykernel_46608\3032259505.py:16: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.
  new_img = img.resize((size), Image.ANTIALIAS)
</code></pre>
<p>The <code>labels</code> returned by the <code>get_augmented_sample</code> is simply the label of the original image for each cropped patch:</p>
<pre class="hljs"><code><div>print(labels)
print(<span class="hljs-string">"Num of labels: "</span>, len(labels))
</div></code></pre>
<pre><code>[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21]
Num of labels:  138
</code></pre>
<p>And the <code>images</code> returned by it are the random patches created from the original image (only two samples shown for simplicity):</p>
<pre class="hljs"><code><div>print(len(images))
plt.imshow(images[<span class="hljs-number">0</span>], cmap =<span class="hljs-string">'gray'</span>)
</div></code></pre>
<pre><code>138





&lt;matplotlib.image.AxesImage at 0x279b253ddf0&gt;
</code></pre>
<p><img src="solution_final_files/solution_final_39_2.png" alt="png"></p>
<pre class="hljs"><code><div>plt.imshow(images[<span class="hljs-number">1</span>], cmap =<span class="hljs-string">'gray'</span>)
</div></code></pre>
<pre><code>&lt;matplotlib.image.AxesImage at 0x279b2165b80&gt;
</code></pre>
<p><img src="solution_final_files/solution_final_40_1.png" alt="png"></p>
<p>The model uses a generator in order to be able to call <code>get_augmented_sample</code> when training the model:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">import</span> operator
<span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> reduce
<span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> to_categorical

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generate_data</span><span class="hljs-params">(samples, labels, batch_size, sample_ratio)</span>:</span>
    <span class="hljs-keyword">while</span> <span class="hljs-number">1</span>: 
        <span class="hljs-keyword">for</span> offset <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, len(samples), batch_size):
            batch_samples = samples[offset:(offset + batch_size)]
            batch_labels = labels[offset:(offset + batch_size)]
            
            <span class="hljs-comment"># Augment each sample in batch</span>
            augmented_batch_samples = []
            augmented_batch_labels = []
            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(batch_samples)):
                sample = batch_samples[i]
                label = batch_labels[i]
                augmented_samples, augmented_labels = get_augmented_sample(sample, label, sample_ratio)
                augmented_batch_samples.append(augmented_samples)
                augmented_batch_labels.append(augmented_labels)

            <span class="hljs-comment"># Flatten out samples and labels</span>
            augmented_batch_samples = reduce(operator.add, augmented_batch_samples)
            augmented_batch_labels = reduce(operator.add, augmented_batch_labels)
            
            <span class="hljs-comment"># Reshape input format</span>
            X_train = np.array(augmented_batch_samples)
            X_train = X_train.reshape(X_train.shape[<span class="hljs-number">0</span>], CROP_SIZE, CROP_SIZE, <span class="hljs-number">1</span>)

            <span class="hljs-comment"># Transform input to float and normalize</span>
            X_train = X_train.astype(<span class="hljs-string">'float32'</span>)
            X_train /= <span class="hljs-number">255</span>

            <span class="hljs-comment"># Encode y</span>
            y_train = np.array(augmented_batch_labels)
            y_train = to_categorical(y_train, NUM_LABELS)

            <span class="hljs-keyword">yield</span> X_train, y_train
</div></code></pre>
<p>Create training, validation, and test generators:</p>
<pre class="hljs"><code><div>train_generator = generate_data(X_train, y_train, BATCH_SIZE, <span class="hljs-number">0.3</span>)
validation_generator = generate_data(X_val, y_val, BATCH_SIZE, <span class="hljs-number">0.3</span>)
test_generator = generate_data(X_test, y_test, BATCH_SIZE, <span class="hljs-number">0.1</span>)
</div></code></pre>
<pre class="hljs"><code><div><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
gpus = tf.config.experimental.list_physical_devices(<span class="hljs-string">'GPU'</span>)
<span class="hljs-keyword">if</span> gpus:
    <span class="hljs-keyword">try</span>:
        <span class="hljs-keyword">for</span> gpu <span class="hljs-keyword">in</span> gpus:
            tf.config.experimental.set_memory_growth(gpu, <span class="hljs-literal">True</span>)
    <span class="hljs-keyword">except</span> RuntimeError <span class="hljs-keyword">as</span> e:
        print(e)
</div></code></pre>
<pre class="hljs"><code><div><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">resize_image</span><span class="hljs-params">(img)</span>:</span>
    size = round(CROP_SIZE/<span class="hljs-number">2</span>)
    <span class="hljs-keyword">return</span> tf.image.resize(img, [size, size])
</div></code></pre>
<p>The model used is exactly the same as the one in the &quot;<a href="https://github.com/priya-dwivedi/Deep-Learning/tree/master/handwriting_recognition">handwriting_recognition</a>&quot; notebook by <a href="https://github.com/priya-dwivedi">Priyanka Dwivedi</a>:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential
<span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Dense, Dropout, Flatten, Lambda, Activation
<span class="hljs-keyword">from</span> keras.layers.convolutional <span class="hljs-keyword">import</span> Convolution2D, ZeroPadding2D, MaxPooling2D
<span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> Adam
<span class="hljs-keyword">from</span> keras <span class="hljs-keyword">import</span> metrics

model = Sequential()

<span class="hljs-comment"># Define network input shape</span>
model.add(ZeroPadding2D((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), input_shape=(CROP_SIZE, CROP_SIZE, <span class="hljs-number">1</span>)))
<span class="hljs-comment"># Resize images to allow for easy computation</span>
model.add(Lambda(resize_image))

<span class="hljs-comment"># CNN model - Building the model suggested in paper</span>
model.add(Convolution2D(filters= <span class="hljs-number">32</span>, kernel_size =(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>), strides= (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=<span class="hljs-string">'same'</span>, name=<span class="hljs-string">'conv1'</span>))
model.add(Activation(<span class="hljs-string">'relu'</span>))
model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), strides=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), name=<span class="hljs-string">'pool1'</span>))

model.add(Convolution2D(filters= <span class="hljs-number">64</span>, kernel_size =(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), strides= (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=<span class="hljs-string">'same'</span>, name=<span class="hljs-string">'conv2'</span>))
model.add(Activation(<span class="hljs-string">'relu'</span>))
model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), strides=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), name=<span class="hljs-string">'pool2'</span>))

model.add(Convolution2D(filters= <span class="hljs-number">128</span>, kernel_size =(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), strides= (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=<span class="hljs-string">'same'</span>, name=<span class="hljs-string">'conv3'</span>))
model.add(Activation(<span class="hljs-string">'relu'</span>))
model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), strides=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), name=<span class="hljs-string">'pool3'</span>))


model.add(Flatten())
model.add(Dropout(<span class="hljs-number">0.5</span>))

model.add(Dense(<span class="hljs-number">512</span>, name=<span class="hljs-string">'dense1'</span>))
model.add(Activation(<span class="hljs-string">'relu'</span>))
model.add(Dropout(<span class="hljs-number">0.5</span>))

model.add(Dense(<span class="hljs-number">256</span>, name=<span class="hljs-string">'dense2'</span>))
model.add(Activation(<span class="hljs-string">'relu'</span>))
model.add(Dropout(<span class="hljs-number">0.5</span>))

model.add(Dense(NUM_LABELS, name=<span class="hljs-string">'output'</span>))
model.add(Activation(<span class="hljs-string">'softmax'</span>))

model.compile(loss=<span class="hljs-string">'categorical_crossentropy'</span>, optimizer=Adam(), metrics=[<span class="hljs-string">'acc'</span>])

print(model.summary())
</div></code></pre>
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 zero_padding2d (ZeroPadding  (None, 115, 115, 1)      0         
 2D)                                                             
                                                                 
 lambda (Lambda)             (None, 56, 56, 1)         0         
                                                                 
 conv1 (Conv2D)              (None, 28, 28, 32)        832       
                                                                 
 activation (Activation)     (None, 28, 28, 32)        0         
                                                                 
 pool1 (MaxPooling2D)        (None, 14, 14, 32)        0         
                                                                 
 conv2 (Conv2D)              (None, 14, 14, 64)        18496     
                                                                 
 activation_1 (Activation)   (None, 14, 14, 64)        0         
                                                                 
 pool2 (MaxPooling2D)        (None, 7, 7, 64)          0         
                                                                 
 conv3 (Conv2D)              (None, 7, 7, 128)         73856     
                                                                 
 activation_2 (Activation)   (None, 7, 7, 128)         0         
                                                                 
 pool3 (MaxPooling2D)        (None, 3, 3, 128)         0         
                                                                 
 flatten (Flatten)           (None, 1152)              0         
                                                                 
 dropout (Dropout)           (None, 1152)              0         
                                                                 
 dense1 (Dense)              (None, 512)               590336    
                                                                 
 activation_3 (Activation)   (None, 512)               0         
                                                                 
 dropout_1 (Dropout)         (None, 512)               0         
                                                                 
 dense2 (Dense)              (None, 256)               131328    
                                                                 
 activation_4 (Activation)   (None, 256)               0         
                                                                 
 dropout_2 (Dropout)         (None, 256)               0         
                                                                 
 output (Dense)              (None, 50)                12850     
                                                                 
 activation_5 (Activation)   (None, 50)                0         
                                                                 
=================================================================
Total params: 827,698
Trainable params: 827,698
Non-trainable params: 0
_________________________________________________________________
None
</code></pre>
<p>Next, the model is trained for 20 epochs and the models obtained after each epoch are saved to the <code>./model_checkpoints</code> directory</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> keras.callbacks <span class="hljs-keyword">import</span> ModelCheckpoint

<span class="hljs-comment"># Create directory to save checkpoints at</span>
model_checkpoints_path = <span class="hljs-string">"./model_checkpoints"</span>
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(model_checkpoints_path):
    os.makedirs(model_checkpoints_path)
    
<span class="hljs-comment"># Save model after every epoch using checkpoints</span>
create_checkpoint = ModelCheckpoint(
    filepath = <span class="hljs-string">"./model_checkpoints/check_{epoch:02d}_{val_loss:.4f}.hdf5"</span>,
    verbose = <span class="hljs-number">1</span>,
    save_best_only = <span class="hljs-literal">False</span>
)

<span class="hljs-comment"># Fit model using generators</span>
history_object = model.fit_generator(
    train_generator, 
    steps_per_epoch = round(len(X_train) / BATCH_SIZE),
    validation_data = validation_generator,
    validation_steps = round(len(X_val) / BATCH_SIZE),
    epochs = <span class="hljs-number">20</span>,
    verbose = <span class="hljs-number">1</span>,
    callbacks = [create_checkpoint]
)
</div></code></pre>
<pre><code>C:\Users\User\AppData\Local\Temp\ipykernel_46608\3366608101.py:16: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.
  history_object = model.fit_generator(
C:\Users\User\AppData\Local\Temp\ipykernel_46608\3032259505.py:16: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.
  new_img = img.resize((size), Image.ANTIALIAS)


Epoch 1/20
196/196 [==============================] - ETA: 0s - loss: 3.4459 - acc: 0.2137
Epoch 1: saving model to ./model_checkpoints\check_01_2.9294.hdf5
196/196 [==============================] - 334s 2s/step - loss: 3.4459 - acc: 0.2137 - val_loss: 2.9294 - val_acc: 0.2694
Epoch 2/20
196/196 [==============================] - ETA: 0s - loss: 2.7850 - acc: 0.2656
Epoch 2: saving model to ./model_checkpoints\check_02_2.3100.hdf5
196/196 [==============================] - 388s 2s/step - loss: 2.7850 - acc: 0.2656 - val_loss: 2.3100 - val_acc: 0.3527
Epoch 3/20
196/196 [==============================] - ETA: 0s - loss: 2.3540 - acc: 0.3343
Epoch 3: saving model to ./model_checkpoints\check_03_2.1663.hdf5
196/196 [==============================] - 393s 2s/step - loss: 2.3540 - acc: 0.3343 - val_loss: 2.1663 - val_acc: 0.3764
Epoch 4/20
196/196 [==============================] - ETA: 0s - loss: 2.0742 - acc: 0.3940
Epoch 4: saving model to ./model_checkpoints\check_04_1.9487.hdf5
196/196 [==============================] - 393s 2s/step - loss: 2.0742 - acc: 0.3940 - val_loss: 1.9487 - val_acc: 0.4229
Epoch 5/20
196/196 [==============================] - ETA: 0s - loss: 1.8527 - acc: 0.4480
Epoch 5: saving model to ./model_checkpoints\check_05_1.5315.hdf5
196/196 [==============================] - 375s 2s/step - loss: 1.8527 - acc: 0.4480 - val_loss: 1.5315 - val_acc: 0.5368
Epoch 6/20
196/196 [==============================] - ETA: 0s - loss: 1.6651 - acc: 0.4953
Epoch 6: saving model to ./model_checkpoints\check_06_1.3693.hdf5
196/196 [==============================] - 387s 2s/step - loss: 1.6651 - acc: 0.4953 - val_loss: 1.3693 - val_acc: 0.5806
Epoch 7/20
196/196 [==============================] - ETA: 0s - loss: 1.5082 - acc: 0.5398
Epoch 7: saving model to ./model_checkpoints\check_07_1.2957.hdf5
196/196 [==============================] - 368s 2s/step - loss: 1.5082 - acc: 0.5398 - val_loss: 1.2957 - val_acc: 0.6016
Epoch 8/20
196/196 [==============================] - ETA: 0s - loss: 1.4060 - acc: 0.5687
Epoch 8: saving model to ./model_checkpoints\check_08_1.2402.hdf5
196/196 [==============================] - 365s 2s/step - loss: 1.4060 - acc: 0.5687 - val_loss: 1.2402 - val_acc: 0.6223
Epoch 9/20
196/196 [==============================] - ETA: 0s - loss: 1.3226 - acc: 0.5937
Epoch 9: saving model to ./model_checkpoints\check_09_1.1062.hdf5
196/196 [==============================] - 358s 2s/step - loss: 1.3226 - acc: 0.5937 - val_loss: 1.1062 - val_acc: 0.6613
Epoch 10/20
196/196 [==============================] - ETA: 0s - loss: 1.2491 - acc: 0.6168
Epoch 10: saving model to ./model_checkpoints\check_10_1.0222.hdf5
196/196 [==============================] - 356s 2s/step - loss: 1.2491 - acc: 0.6168 - val_loss: 1.0222 - val_acc: 0.6847
Epoch 11/20
196/196 [==============================] - ETA: 0s - loss: 1.1783 - acc: 0.6375
Epoch 11: saving model to ./model_checkpoints\check_11_0.9577.hdf5
196/196 [==============================] - 366s 2s/step - loss: 1.1783 - acc: 0.6375 - val_loss: 0.9577 - val_acc: 0.7061
Epoch 12/20
196/196 [==============================] - ETA: 0s - loss: 1.1203 - acc: 0.6556
Epoch 12: saving model to ./model_checkpoints\check_12_0.9189.hdf5
196/196 [==============================] - 361s 2s/step - loss: 1.1203 - acc: 0.6556 - val_loss: 0.9189 - val_acc: 0.7194
Epoch 13/20
196/196 [==============================] - ETA: 0s - loss: 1.0756 - acc: 0.6696
Epoch 13: saving model to ./model_checkpoints\check_13_0.8940.hdf5
196/196 [==============================] - 360s 2s/step - loss: 1.0756 - acc: 0.6696 - val_loss: 0.8940 - val_acc: 0.7260
Epoch 14/20
196/196 [==============================] - ETA: 0s - loss: 1.0372 - acc: 0.6811
Epoch 14: saving model to ./model_checkpoints\check_14_0.9065.hdf5
196/196 [==============================] - 347s 2s/step - loss: 1.0372 - acc: 0.6811 - val_loss: 0.9065 - val_acc: 0.7184
Epoch 15/20
196/196 [==============================] - ETA: 0s - loss: 0.9920 - acc: 0.6955
Epoch 15: saving model to ./model_checkpoints\check_15_0.8637.hdf5
196/196 [==============================] - 358s 2s/step - loss: 0.9920 - acc: 0.6955 - val_loss: 0.8637 - val_acc: 0.7336
Epoch 16/20
196/196 [==============================] - ETA: 0s - loss: 0.9524 - acc: 0.7072
Epoch 16: saving model to ./model_checkpoints\check_16_0.7901.hdf5
196/196 [==============================] - 390s 2s/step - loss: 0.9524 - acc: 0.7072 - val_loss: 0.7901 - val_acc: 0.7580
Epoch 17/20
196/196 [==============================] - ETA: 0s - loss: 0.9241 - acc: 0.7159
Epoch 17: saving model to ./model_checkpoints\check_17_0.7386.hdf5
196/196 [==============================] - 355s 2s/step - loss: 0.9241 - acc: 0.7159 - val_loss: 0.7386 - val_acc: 0.7745
Epoch 18/20
196/196 [==============================] - ETA: 0s - loss: 0.8996 - acc: 0.7240
Epoch 18: saving model to ./model_checkpoints\check_18_0.7276.hdf5
196/196 [==============================] - 360s 2s/step - loss: 0.8996 - acc: 0.7240 - val_loss: 0.7276 - val_acc: 0.7780
Epoch 19/20
196/196 [==============================] - ETA: 0s - loss: 0.8938 - acc: 0.7259
Epoch 19: saving model to ./model_checkpoints\check_19_0.8167.hdf5
196/196 [==============================] - 353s 2s/step - loss: 0.8938 - acc: 0.7259 - val_loss: 0.8167 - val_acc: 0.7484
Epoch 20/20
196/196 [==============================] - ETA: 0s - loss: 0.8745 - acc: 0.7315
Epoch 20: saving model to ./model_checkpoints\check_20_0.7311.hdf5
196/196 [==============================] - 359s 2s/step - loss: 0.8745 - acc: 0.7315 - val_loss: 0.7311 - val_acc: 0.7771
</code></pre>
<p>Load a saved model weights and use them to predict labels in the test set:</p>
<pre class="hljs"><code><div>model_weights_path = <span class="hljs-string">"./model_checkpoints/model_weights.hdf5"</span>
<span class="hljs-keyword">if</span> model_weights_path:
    model.load_weights(model_weights_path)
    scores = model.evaluate_generator(test_generator, steps=round(len(X_test)/BATCH_SIZE))
    print(<span class="hljs-string">"Accuracy: "</span>, scores[<span class="hljs-number">1</span>])
<span class="hljs-keyword">else</span>:
    print(<span class="hljs-string">"Set model weights file to load in the 'model_weights_path' variable"</span>)
</div></code></pre>
<pre><code>C:\Users\User\AppData\Local\Temp\ipykernel_46608\1622692593.py:4: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.
  scores = model.evaluate_generator(test_generator, steps=round(len(X_test)/BATCH_SIZE))
C:\Users\User\AppData\Local\Temp\ipykernel_46608\3032259505.py:16: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.
  new_img = img.resize((size), Image.ANTIALIAS)


Accuracy:  0.704222559928894
</code></pre>

</body>
</html>
